{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1cea67aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ftfy import fix_text #removes â€¦ â€™ â€“\n",
    "from bs4 import BeautifulSoup # strips any leftover HTML safely\n",
    "from cleantext import clean #gives you ready-made toggles: remove any URLS, emojis, phone\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pathlib import Path\n",
    "from sentence_transformers import CrossEncoder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ffa0c",
   "metadata": {},
   "source": [
    "DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12c7e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(s): \n",
    "    return BeautifulSoup(s or \"\", \"html.parser\").get_text(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "560f3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ez_clean(s: str) -> str:\n",
    "    s = fix_text(s or \"\")                     # fixes Ã¢â‚¬… mojibake\n",
    "    s = strip_html(s)                         # removes HTML tags\n",
    "    s = clean(                                # turnkey switches\n",
    "        s, \n",
    "        lower=True,\n",
    "        no_urls=True, no_emails=True, no_phone_numbers=True,\n",
    "        no_currency_symbols=True, no_emoji=True, no_line_breaks=True,\n",
    "        fix_unicode=True\n",
    "    )\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f226552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use it on your files (edit paths if needed)\n",
    "res = pd.read_csv(r\"D:\\HR Agent\\data\\resume.csv\")\n",
    "jobs = pd.read_csv(r\"D:\\HR Agent\\data\\job_des.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81f1ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"Category\"]   = res[\"Category\"].map(ez_clean)\n",
    "res[\"Resume\"]     = res[\"Resume\"].map(ez_clean)\n",
    "jobs[\"Job Title\"] = jobs[\"Job Title\"].map(ez_clean)\n",
    "jobs[\"Description\"]= jobs[\"Description\"].map(ez_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35d4c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: drop dups & very short rows\n",
    "res = res.drop_duplicates(subset=[\"Resume\"])\n",
    "jobs = jobs.drop_duplicates(subset=[\"Job Title\",\"Description\"])\n",
    "res = res[res[\"Resume\"].str.len() >= 80]\n",
    "jobs = jobs[jobs[\"Description\"].str.len() >= 80]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8344f910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: resume_clean_auto.csv, job_des_clean_auto.csv\n"
     ]
    }
   ],
   "source": [
    "res.to_csv(r\"D:\\HR Agent\\data\\resume_clean_auto.csv\", index=False)\n",
    "jobs.to_csv(r\"D:\\HR Agent\\data\\job_des_clean_auto.csv\", index=False)\n",
    "\n",
    "print(\"Saved: resume_clean_auto.csv, job_des_clean_auto.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73dd354",
   "metadata": {},
   "source": [
    "EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9f3349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- paths \n",
    "DATA_DIR = Path(r\"D:\\HR Agent\\data\")\n",
    "ART_DIR  = Path(r\"D:\\HR Agent\\artifacts\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "88cac8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your cleaned resumes\n",
    "res_path = DATA_DIR / \"resume_clean_v2.csv\"   # or resume_clean_auto.csv / resume_clean.csv\n",
    "res = pd.read_csv(res_path)                   # expects columns: Category, Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ad30603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to embed = the resume text\n",
    "texts = res[\"Resume\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# Same model as JDs\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "22bf1504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:03<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# --- embed with a small, strong model ---\n",
    "emb = model.encode(\n",
    "    texts,\n",
    "    convert_to_numpy=True,\n",
    "    normalize_embeddings=True,   # cosine via inner product\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb228d",
   "metadata": {},
   "source": [
    "BUILT FAISS INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "71d03bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS index (cosine with normalized vectors)\n",
    "index = faiss.IndexFlatIP(emb.shape[1])\n",
    "index.add(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b6b7e611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved:\n",
      "D:\\HR Agent\\artifacts\\resume_index.faiss\n",
      "D:\\HR Agent\\artifacts\\resume_embeddings.npy\n",
      "D:\\HR Agent\\artifacts\\resume_meta.csv\n",
      "Total resumes indexed: 166\n"
     ]
    }
   ],
   "source": [
    "# Persist index + metadata\n",
    "faiss.write_index(index, str(ART_DIR / \"resume_index.faiss\"))\n",
    "np.save(ART_DIR / \"resume_embeddings.npy\", emb)\n",
    "res.to_csv(ART_DIR / \"resume_meta.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Saved:\")\n",
    "print(ART_DIR / \"resume_index.faiss\")\n",
    "print(ART_DIR / \"resume_embeddings.npy\")\n",
    "print(ART_DIR / \"resume_meta.csv\")\n",
    "print(\"Total resumes indexed:\", len(res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcca662",
   "metadata": {},
   "source": [
    "QUICK SANITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f029fb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index vectors: 519\n",
      "Embedding dim: 384\n",
      "Meta rows: 519\n",
      "Query JD/keywords: data analyst\n",
      "                                  Job Title     score\n",
      "0                              data analyst  1.000000\n",
      "1                              data analyst  0.755119\n",
      "2  data reporting analyst- (***york, pa***)  0.747314\n",
      "3                       junior data analyst  0.742687\n",
      "4                              data analyst  0.741027\n"
     ]
    }
   ],
   "source": [
    "ART = r\"D:\\HR Agent\\artifacts\"\n",
    "\n",
    "# Load index + metadata\n",
    "index = faiss.read_index(fr\"{ART}\\jd_index.faiss\")\n",
    "meta  = pd.read_csv(fr\"{ART}\\jd_meta.csv\")  # columns: Job Title, Description, text\n",
    "\n",
    "print(\"Index vectors:\", index.ntotal)\n",
    "print(\"Embedding dim:\", index.d)\n",
    "print(\"Meta rows:\", len(meta))\n",
    "assert len(meta) == index.ntotal, \"Meta rows must equal index size!\"\n",
    "\n",
    "# ----- sanity query by KEYWORDS -----\n",
    "KEYWORDS = \"data analyst\"  # <--- change this\n",
    "\n",
    "# Prefer title match; fallback to description; final fallback: use keywords as-is\n",
    "title_mask = meta[\"Job Title\"].fillna(\"\").str.contains(KEYWORDS, case=False, regex=False)\n",
    "desc_mask  = meta[\"Description\"].fillna(\"\").str.contains(KEYWORDS, case=False, regex=False)\n",
    "\n",
    "if title_mask.any():\n",
    "    seed = meta[title_mask].iloc[0]\n",
    "elif desc_mask.any():\n",
    "    seed = meta[desc_mask].iloc[0]\n",
    "else:\n",
    "    seed = {\"Job Title\": f\"(no exact JD match) :: {KEYWORDS}\", \"text\": KEYWORDS}\n",
    "\n",
    "q_text = seed.get(\"text\", KEYWORDS)\n",
    "\n",
    "# Encode & search\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "q_emb  = model.encode([q_text], convert_to_numpy=True, normalize_embeddings=True)\n",
    "D, I   = index.search(q_emb, 5)\n",
    "\n",
    "# Show top matches\n",
    "out = meta.iloc[I[0]][[\"Job Title\"]].copy()\n",
    "out[\"score\"] = D[0]\n",
    "print(\"Query JD/keywords:\", seed[\"Job Title\"])\n",
    "print(out.reset_index(drop=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f1c847",
   "metadata": {},
   "source": [
    "QUERY INDEX WITH REAL RESUME AND LIST THE TOP-K MATCHING JDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- paths\n",
    "ART_DIR = r\"D:\\HR Agent\\artifacts\"\n",
    "DATA_DIR = r\"D:\\HR Agent\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "048391d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load resume index + meta\n",
    "r_index = faiss.read_index(fr\"{ART_DIR}\\resume_index.faiss\")\n",
    "r_meta  = pd.read_csv(fr\"{ART_DIR}\\resume_meta.csv\")   # has Category, Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64bb1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JDs to choose from\n",
    "jobs = pd.read_csv(fr\"{DATA_DIR}\\job_des_clean_auto.csv\")  # has Job Title, Description\n",
    "jobs[\"text\"] = (jobs[\"Job Title\"].fillna(\"\") + \" - \" + jobs[\"Description\"].fillna(\"\")).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b783a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same embedder as used to build the index\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "def search_candidates_for_jd(jd_text: str, k: int = 10) -> pd.DataFrame:\n",
    "    q = model.encode([jd_text], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    D, I = r_index.search(q, k)\n",
    "    out = r_meta.iloc[I[0]].copy()\n",
    "    out[\"score\"] = D[0]\n",
    "    # show a short preview of the resume text\n",
    "    out[\"resume_preview\"] = out[\"Resume\"].str.slice(0, 220) + \"...\"\n",
    "    return out[[\"Category\", \"resume_preview\", \"score\"]].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da8cbd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD: data analyst\n",
      "           Category                                     resume_preview  \\\n",
      "0      Data Science  expertise - data and quantitative analysis - d...   \n",
      "1      Data Science  skills * python * tableau * data visualization...   \n",
      "2     Etl Developer  computer skills: - yes. sql knowledge-yes unix...   \n",
      "3     Etl Developer  skill set talend big data informatica power ce...   \n",
      "4  Python Developer  technical skills / responsibilities: * hands o...   \n",
      "5  Business Analyst  key skills - requirement gathering - requireme...   \n",
      "6  Python Developer  * operating systems: windows * others: ms exce...   \n",
      "7             Sales  skills 1. ms-office 2. good communication skil...   \n",
      "8               Pmo  area of expertise (profile) around 10 plus yea...   \n",
      "9     Sap Developer  education details january 2016 bachelor of eng...   \n",
      "\n",
      "      score  \n",
      "0  0.596651  \n",
      "1  0.577712  \n",
      "2  0.556203  \n",
      "3  0.537110  \n",
      "4  0.536817  \n",
      "5  0.527484  \n",
      "6  0.523135  \n",
      "7  0.521917  \n",
      "8  0.519749  \n",
      "9  0.514907  \n"
     ]
    }
   ],
   "source": [
    "# Pick a JD by title keywords (fallback: search in description)\n",
    "KEYWORDS = \"data analyst\"  # <-- change this\n",
    "\n",
    "hits = jobs[jobs[\"Job Title\"].str.contains(KEYWORDS, case=False, na=False, regex=False)]\n",
    "if hits.empty:\n",
    "    hits = jobs[jobs[\"Description\"].str.contains(KEYWORDS, case=False, na=False, regex=False)]\n",
    "    assert not hits.empty, f\"No JD title/description contains: {KEYWORDS}\"\n",
    "\n",
    "hit = hits.iloc[0]                 # take the first match; or hits.sample(1).iloc[0]\n",
    "jd_text = hit[\"text\"]\n",
    "\n",
    "print(\"JD:\", hit[\"Job Title\"])\n",
    "results = search_candidates_for_jd(jd_text, k=10)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93237f5e",
   "metadata": {},
   "source": [
    "RE-RANK FAISS RESULTS WITH A CROSSENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "20c24f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ensure your search returns full Resume text for re-ranking ---\n",
    "def search_candidates_for_jd(jd_text: str, k: int = 20) -> pd.DataFrame:\n",
    "    q = model.encode([jd_text], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    D, I = r_index.search(q, k)\n",
    "    out = r_meta.iloc[I[0]][[\"Category\",\"Resume\"]].copy()\n",
    "    out[\"bi_score\"] = D[0]  # bi-encoder score (from FAISS)\n",
    "    out[\"resume_preview\"] = out[\"Resume\"].str.slice(0, 220) + \"...\"\n",
    "    return out\n",
    "\n",
    "# --- cross-encoder (reads JD + Resume together) ---\n",
    "ce = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")  # downloads on first use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d38b9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_crossencoder(jd_text: str, cand_df, top_m: int = 10):\n",
    "    pairs = [(jd_text, t) for t in cand_df[\"Resume\"].tolist()]\n",
    "    logits = ce.predict(pairs)  # raw scores (can be negative)\n",
    "    probs = torch.sigmoid(torch.tensor(logits)).numpy()  # 0..1\n",
    "\n",
    "    df = cand_df.copy()\n",
    "    df[\"ce_logit\"] = logits\n",
    "    df[\"ce_prob\"]  = probs\n",
    "    df = df.sort_values(\"ce_prob\", ascending=False).head(top_m)\n",
    "    return df[[\"Category\", \"resume_preview\", \"bi_score\", \"ce_prob\"]].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2bd671d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JD: data analyst\n",
      "           Category                                     resume_preview  \\\n",
      "0               Pmo  core competencies * maintain processes to ensu...   \n",
      "1      Data Science  expertise - data and quantitative analysis - d...   \n",
      "2      Data Science  skills * python * tableau * data visualization...   \n",
      "3      Data Science  skills * r * python * sap hana * tableau * sap...   \n",
      "4      Data Science  skills * programming languages: python (pandas...   \n",
      "5               Pmo  area of expertise (profile) around 10 plus yea...   \n",
      "6  Business Analyst  key skills - requirement gathering - requireme...   \n",
      "7     Sap Developer  skills: * etl * data warehousing * sql/pl sql ...   \n",
      "8     Etl Developer  technical summary * knowledge of informatica p...   \n",
      "9  Business Analyst  education details february 2006 to february 20...   \n",
      "\n",
      "   bi_score   ce_prob  \n",
      "0  0.508532  0.003384  \n",
      "1  0.596651  0.002780  \n",
      "2  0.577712  0.002076  \n",
      "3  0.494516  0.001896  \n",
      "4  0.509494  0.001056  \n",
      "5  0.519749  0.000671  \n",
      "6  0.527484  0.000653  \n",
      "7  0.467019  0.000452  \n",
      "8  0.506296  0.000441  \n",
      "9  0.493185  0.000394  \n"
     ]
    }
   ],
   "source": [
    "KEYWORDS = \"data analyst\"   # <-- your JD keywords\n",
    "hits = jobs[jobs[\"Job Title\"].str.contains(KEYWORDS, case=False, na=False, regex=False)]\n",
    "if hits.empty:\n",
    "    hits = jobs[jobs[\"Description\"].str.contains(KEYWORDS, case=False, na=False, regex=False)]\n",
    "hit = hits.iloc[0]\n",
    "jd_text = hit[\"text\"]\n",
    "print(\"JD:\", hit[\"Job Title\"])\n",
    "\n",
    "cands = search_candidates_for_jd(jd_text, k=25)   # recall\n",
    "final = rerank_with_crossencoder(jd_text, cands, top_m=10)  # precision\n",
    "print(final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
