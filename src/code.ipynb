{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2004a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "from pydantic import BaseModel, field_validator\n",
    "import optional\n",
    "from typing import Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import re, unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368173c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- paths ----------\n",
    "JOB = r\"D:\\HR Agent\\data\\job.csv\"\n",
    "RES = r\"D:\\HR Agent\\data\\resume.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0678ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- helpers ----------\n",
    "def clean_text(s: object) -> str:\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s)\n",
    "\n",
    "    # fix common mojibake quickly (works even without extra libs)\n",
    "    s = (s.replace(\"Â\", \" \")\n",
    "           .replace(\"â€™\", \"'\")\n",
    "           .replace(\"â€œ\", '\"')\n",
    "           .replace(\"â€\\x9d\", '\"')\n",
    "           .replace(\"â€“\", \"-\")\n",
    "           .replace(\"â€”\", \"-\")\n",
    "           .replace(\"â€¢\", \" \")\n",
    "           .replace(\"\\xa0\", \" \"))\n",
    "\n",
    "    s = unicodedata.normalize(\"NFC\", s)\n",
    "\n",
    "    # strip HTML + URLs + emails + phones\n",
    "    s = re.sub(r\"<[^>]+>\", \" \", s)\n",
    "    s = re.sub(r\"(https?://\\S+|www\\.\\S+|#URL_\\w+)\", \" \", s)\n",
    "    s = re.sub(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\", \" \", s)\n",
    "    s = re.sub(r\"\\+?\\d[\\d\\-\\s\\(\\)]{7,}\\d\", \" \", s)\n",
    "\n",
    "    # collapse whitespace + lowercase\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754437b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- load (handle encodings) ----------\n",
    "def safe_read(path):\n",
    "    for enc in (\"utf-8\", \"utf-8-sig\", \"latin1\"):\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    # last resort\n",
    "    return pd.read_csv(path, encoding_errors=\"ignore\")\n",
    "\n",
    "job_df = safe_read(JOB)\n",
    "resume_df = safe_read(RES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d74c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- JOB CLEAN ----------\n",
    "for col in [\"title\", \"description\", \"requirements\"]:\n",
    "    if col not in job_df.columns:\n",
    "        job_df[col] = \"\"\n",
    "    job_df[col] = job_df[col].apply(clean_text)\n",
    "\n",
    "job_df[\"job_text\"] = (\n",
    "    job_df[\"title\"] + \" \" + job_df[\"description\"] + \" \" + job_df[\"requirements\"]\n",
    ").str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "job_df = job_df[job_df[\"job_text\"].str.len() > 20]\n",
    "job_df = job_df.drop_duplicates(subset=[\"job_text\"])\n",
    "\n",
    "# ---------- RESUME CLEAN ----------\n",
    "# ensure expected names\n",
    "resume_df = resume_df.rename(columns={\"Category\": \"category\", \"Resume\": \"resume\"})\n",
    "if \"resume\" not in resume_df.columns:\n",
    "    raise KeyError(f\"Could not find resume text column. Columns: {list(resume_df.columns)}\")\n",
    "\n",
    "resume_df[\"category\"] = resume_df.get(\"category\", \"unknown\").apply(clean_text)\n",
    "resume_df[\"resume_text\"] = resume_df[\"resume\"].apply(clean_text)\n",
    "\n",
    "resume_df = resume_df[resume_df[\"resume_text\"].str.len() > 20]\n",
    "resume_df = resume_df.drop_duplicates(subset=[\"resume_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ba0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- SAVE ----------\n",
    "job_out = r\"D:\\HR Agent\\data\\job_cleaned.csv\"\n",
    "res_out = r\"D:\\HR Agent\\data\\resume_cleaned.csv\"\n",
    "job_df.to_csv(job_out, index=False)\n",
    "resume_df.to_csv(res_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2981880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs cleaned: 15736 -> D:\\HR Agent\\data\\job_cleaned.csv\n",
      "resumes cleaned: 166 -> D:\\HR Agent\\data\\resume_cleaned.csv\n",
      "\n",
      "Sample job_text:\n",
      " marketing intern food52, a fast-growing, james ...\n",
      "customer service - cloud video production organ...\n",
      "\n",
      "Sample resume_text:\n",
      " skills * programming languages: python (pandas,...\n",
      "education details may 2013 to may 2017 b.e uit-...\n"
     ]
    }
   ],
   "source": [
    "print(f\"jobs cleaned: {len(job_df)} -> {job_out}\")\n",
    "print(f\"resumes cleaned: {len(resume_df)} -> {res_out}\")\n",
    "print(\"\\nSample job_text:\\n\", job_df[\"job_text\"].head(2).to_string(index=False))\n",
    "print(\"\\nSample resume_text:\\n\", resume_df[\"resume_text\"].head(2).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
